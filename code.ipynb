{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialization\n",
    "#### 3 dictionary for unygram of each poet\n",
    "#### 3 dictionary for bygram of each poet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "hafez={}\n",
    "ferdowsi={}\n",
    "molavi={}\n",
    "hafez2={}\n",
    "ferdowsi2={}\n",
    "molavi2={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_set/hafez_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for word in line:\n",
    "            if word in hafez:\n",
    "                hafez[word]=hafez.get(word)+1\n",
    "            else:\n",
    "                hafez[word]=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_set/ferdowsi_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for word in line:\n",
    "            if word in ferdowsi:\n",
    "                ferdowsi[word]=ferdowsi.get(word)+1\n",
    "            else:\n",
    "                ferdowsi[word]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_set/molavi_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for word in line:\n",
    "            if word in molavi:\n",
    "                molavi[word]=molavi.get(word)+1\n",
    "            else:\n",
    "                molavi[word]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"train_set/ferdowsi_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for i in range(len(line)):\n",
    "            if i == len(line)-1:\n",
    "                twoWords=line[i]+' <>'\n",
    "            else:\n",
    "                twoWords=line[i]+' '+line[i+1]\n",
    "            if twoWords in hafez2:\n",
    "                ferdowsi2[twoWords]=hafez2.get(twoWords)+1\n",
    "            else:\n",
    "                ferdowsi2[twoWords]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_set/hafez_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for i in range(len(line)):\n",
    "            if i == len(line)-1:\n",
    "                twoWords=line[i]+' <>'\n",
    "            else:\n",
    "                twoWords=line[i]+' '+line[i+1]\n",
    "            if twoWords in hafez2:\n",
    "                hafez2[twoWords]=hafez2.get(twoWords)+1\n",
    "            else:\n",
    "                hafez2[twoWords]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_set/molavi_train.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        line=line.replace('،',' ')\n",
    "        line=line.split()\n",
    "        for i in range(len(line)):\n",
    "            if i == len(line)-1:\n",
    "                twoWords=line[i]+' <>'\n",
    "            else:\n",
    "                twoWords=line[i]+' '+line[i+1]\n",
    "            if twoWords in hafez2:\n",
    "                molavi2[twoWords]=hafez2.get(twoWords)+1\n",
    "            else:\n",
    "                molavi2[twoWords]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleans the data\n",
    "### omit words with les frequency than two times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key, value in hafez.items():\n",
    "    if value > 2:\n",
    "        new_dict[key] = value\n",
    "hafez = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key, value in ferdowsi.items():\n",
    "    if value > 2:\n",
    "        new_dict[key] = value\n",
    "ferdowsi = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for key, value in molavi.items():\n",
    "    if value > 2:\n",
    "        new_dict[key] = value\n",
    "molavi = new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "poets=[]\n",
    "poems=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_set/test_case.txt\", encoding=\"utf8\") as reader:\n",
    "    for line in reader:\n",
    "        s=line.split('\\t')\n",
    "        poets.append(s[0])\n",
    "        poems.append(s[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  backoff calculate probability of a wordin entern unygram and bygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff(w1,w2,unygram,bygram,lambda1,lambda2,lambda3,beta):\n",
    "    resault=0\n",
    "    ww=w1+' '+w2\n",
    "    \n",
    "    if ww in bygram and w1 in unygram:\n",
    "        \n",
    "        resault = lambda1*bygram.get(ww)/unygram.get(w1)\n",
    "    if w1 in unygram:\n",
    "        resault+=lambda2*unygram.get(w1)/len(unygram.keys())\n",
    "    resault+=lambda3*beta\n",
    "    return resault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of a poem to be for a poet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def howMuchIn(poem,unigram,bygram,lambda1,lambda2,lambda3,beta):\n",
    "    poem=poem.split()\n",
    "    prob=0\n",
    "\n",
    "    for i in range(len(poem)):\n",
    "        if i==len(poem)-1:\n",
    "            prob+=backoff(poem[i],'<>',unigram,bygram,lambda1,lambda2,lambda3,beta)\n",
    "        else:\n",
    "            prob+=backoff(poem[i],poem[i+1],unigram,bygram,lambda1,lambda2,lambda3,beta)\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  poem is for which poet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichOne(poem,lambda1,lambda2,lambda3,beta):\n",
    "    probF = howMuchIn(poem,ferdowsi,ferdowsi2,lambda1[0],lambda2[0],lambda3[0],beta[0])\n",
    "    probH = howMuchIn(poem,hafez,hafez2,lambda1[1],lambda2[1],lambda3[1],beta[1])\n",
    "    probM = howMuchIn(poem,molavi,molavi2,lambda1[2],lambda2[2],lambda3[2],beta[2])\n",
    "    m=max(probF,probH,probM)\n",
    "    #print(probF,probH,probM)\n",
    "    if probF==m:\n",
    "        return '1'\n",
    "    if probH==m:\n",
    "        return '2'\n",
    "    return '3'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset is not balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28006 37632 34916\n",
      "2153 2623 2374\n"
     ]
    }
   ],
   "source": [
    "print(len(ferdowsi2.keys()),len(hafez2.keys()),len(molavi2.keys()))\n",
    "            \n",
    "print(len(ferdowsi.keys()),len(hafez.keys()),len(molavi.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lambda trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxLambda(lambda1,lambda2,lambda3,beta):\n",
    "    val=[[0,0,0],[0,0,0],[0,0,0]]\n",
    "    for i in range(len(poems)):\n",
    "        temp = whichOne(poems[i],lambda1,lambda2,lambda3,beta)\n",
    "        \n",
    "        if poets[i] == temp:\n",
    "            val[1][int(temp)-1]+=1\n",
    "        else:\n",
    "            val[2][int(temp)-1]+=1\n",
    "        val[0][int(poets[i])-1]+=1\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(a):\n",
    "    return 100*sum(a)/138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [17, 24, 27] [10, 32, 28]\n",
      "49.27536231884058\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.99,0.99,0.99],[0.005,0.005,0.003],[0.01,0.0051,0.007],[0.1,0.0001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [18, 16, 36] [17, 30, 21]\n",
      "50.72463768115942\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.15,0.15,0.15],[0.75,0.75,0.75],[0.01,0.0051,0.007],[0.1,0.0001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [28, 22, 24] [23, 24, 17]\n",
      "53.6231884057971\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.75,0.75,0.75],[0.25,0.15,0.15],[0.01,0.0001,0.007],[0.1,0.0001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [16, 25, 36] [8, 34, 19]\n",
      "55.79710144927536\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.59,0.6,0.59],[0.39,0.4,0.39],[0.003,0.001,0.01],[0.02,0.001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [25, 15, 37] [19, 27, 15]\n",
      "55.79710144927536\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.005,0.005,0.003],[0.99,0.99,0.99],[0.01,0.0051,0.007],[0.1,0.0001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [18, 23, 38] [8, 32, 19]\n",
      "57.2463768115942\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.39,0.4,0.39],[0.59,0.6,0.59],[0.003,0.001,0.01],[0.02,0.001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [19, 23, 36] [10, 31, 19]\n",
      "56.52173913043478\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.49,0.4,0.39],[0.59,0.6,0.59],[0.003,0.001,0.01],[0.02,0.001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [23, 20, 37] [10, 24, 24]\n",
      "57.971014492753625\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.50,0.65,0.50],[0.49,0.349,0.49],[0.01,0.001,0.01],[0.02,0.001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 35, 53] [15, 25, 31] [4, 34, 29]\n",
      "51.44927536231884\n"
     ]
    }
   ],
   "source": [
    "_,t,f = maxLambda([0.9,0.9,0.9],[0.05,0.05,0.05],[0.05,0.05,0.05],[0.001,0.00001,0.001])\n",
    "print(_,t,f)\n",
    "print(p(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
